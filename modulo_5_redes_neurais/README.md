# üß† M√≥dulo 5: Redes Neurais - Otimiza√ß√£o Visual

## üìã Vis√£o Geral

Este m√≥dulo oferece uma experi√™ncia interativa e visual para entender como algoritmos de otimiza√ß√£o funcionam em redes neurais. Explore curvas de erro em 3D, trajet√≥rias de otimiza√ß√£o e exerc√≠cios pr√°ticos com c√≥digo execut√°vel.

## üéØ Funcionalidades Principais

### üìä Visualiza√ß√£o Interativa da Curva de Erro
- **Gr√°ficos 3D** da superf√≠cie de perda com Plotly
- **Trajet√≥ria em tempo real** mostrando como os par√¢metros evoluem
- **Controles interativos**: learning rate, momentum, n√∫mero de √©pocas
- **Compara√ß√£o de otimizadores**: GD, SGD, Adam

### üéÆ Exerc√≠cios Interativos
- **Sandbox de c√≥digo Python** com execu√ß√£o segura
- **Valida√ß√£o autom√°tica** de algoritmos implementados
- **Feedback contextual** com dicas e corre√ß√µes
- **Sistema de pontua√ß√£o** e progresso

### üîó Integra√ß√£o com GitHub
- **Busca de exemplos reais** de redes neurais
- **Documenta√ß√£o t√©cnica** via API GitHub
- **C√≥digo de refer√™ncia** de reposit√≥rios populares

## üöÄ Como Usar

### 1. Visualiza√ß√£o B√°sica
```python
from modulo_5_redes_neurais import otimizadores, visualizacoes

# Criar otimizador
otimizador = otimizadores.Adam(learning_rate=0.01)

# Executar otimiza√ß√£o
historico = otimizadores.otimizar_rede_simples(X, y, otimizador, epocas=100)

# Visualizar
fig = visualizacoes.plot_curva_erro_2d(historico, X, y)
fig.show()
```

### 2. Exerc√≠cios Pr√°ticos
```python
from modulo_5_redes_neurais.exercicios import ExercicioGradienteDescendente

# Criar exerc√≠cio
exercicio = ExercicioGradienteDescendente()

# Na interface Streamlit
exercicio.criar_interface_exercicio()
```

### 3. Busca no GitHub
```python
from gitmcp_integration import GitMCPIntegration

git_client = GitMCPIntegration()
resultados = git_client.buscar_documentacao_algoritmo("neural network optimization")
```

## üìö Algoritmos Implementados

### Otimizadores
- **Gradiente Descendente**: Atualiza√ß√£o b√°sica de par√¢metros
- **SGD com Momentum**: Acelera√ß√£o da converg√™ncia
- **Adam**: Adaptativo com momento e vari√¢ncia

### Fun√ß√µes de Perda
- **MSE (Mean Squared Error)**: Para regress√£o
- **Extens√≠vel**: F√°cil adicionar outras perdas

## üé® Interface Streamlit

O m√≥dulo se integra completamente ao `app_integrada.py` como **M√≥dulo 5: Redes Neurais** na navega√ß√£o principal.

### Abas Dispon√≠veis
1. **üìä Visualiza√ß√£o Interativa** - Explore otimizadores em tempo real
2. **üéÆ Exerc√≠cios Pr√°ticos** - Aprenda implementando algoritmos
3. **üìö Exemplos do GitHub** - Veja c√≥digo real de projetos
4. **‚öôÔ∏è Configura√ß√µes** - Personalize a experi√™ncia

## üîß Depend√™ncias

```txt
numpy>=1.24.0
matplotlib>=3.7.0
plotly>=5.15.0
streamlit>=1.32.0
```

## üìñ Exemplos de Uso

### Compara√ß√£o de Otimizadores
```python
import numpy as np
from modulo_5_redes_neurais import otimizadores, visualizacoes

# Dados de exemplo
X = np.random.randn(100, 1)
y = 2 * X.flatten() + 1 + 0.1 * np.random.randn(100)

# Comparar otimizadores
otimizadores_teste = [
    otimizadores.GradienteDescendente(learning_rate=0.1),
    otimizadores.SGD(learning_rate=0.1, momentum=0.9),
    otimizadores.Adam(learning_rate=0.01)
]

for otimizador in otimizadores_teste:
    historico = otimizadores.otimizar_rede_simples(X, y, otimizador, epocas=50)
    print(f"{otimizador.__class__.__name__}: Perda final = {historico['loss'][-1]:.4f}")
```

## üéØ Objetivos de Aprendizado

Ap√≥s completar este m√≥dulo, voc√™ ser√° capaz de:

1. **Entender visualmente** como otimizadores funcionam
2. **Comparar algoritmos** de otimiza√ß√£o diferentes
3. **Implementar** gradiente descendente do zero
4. **Diagnosticar** problemas de converg√™ncia
5. **Aplicar** conceitos em problemas reais

## üîÑ Pr√≥ximos Passos

- [ ] Adicionar mais otimizadores (RMSProp, AdaGrad)
- [ ] Implementar redes neurais multicamadas
- [ ] Adicionar visualiza√ß√£o de overfitting/underfitting
- [ ] Integrar com datasets reais (MNIST, CIFAR)
- [ ] Sistema de exerc√≠cios mais avan√ßado

## ü§ù Contribui√ß√£o

Para contribuir com este m√≥dulo:

1. Adicione novos otimizadores em `otimizadores.py`
2. Crie exerc√≠cios em `exercicios.py`
3. Implemente visualiza√ß√µes em `visualizacoes.py`
4. Teste a integra√ß√£o no `app_integrada.py`

## üìÑ Licen√ßa

Este m√≥dulo faz parte do projeto [Algoritmos Visualizador](https://github.com/dronreef2/algoritmos-visualizador) e segue a mesma licen√ßa.