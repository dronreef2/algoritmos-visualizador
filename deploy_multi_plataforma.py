"""
üéØ M√≥dulo de Deploy Multi-Plataforma
====================================

M√≥dulo integrado √† aplica√ß√£o Streamlit que fornece:
- Detec√ß√£o autom√°tica de plataforma
- Op√ß√µes de deploy para diferentes clouds
- Status de recursos e compatibilidade
- Guias de migra√ß√£o entre plataformas
- CONTROLE DIRETO: Executar verifica√ß√µes, configura√ß√µes e inicializa√ß√µes

Integrado ao app_integrada.py para fornecer experi√™ncia unificada.
"""

import streamlit as st
import os
import platform
from pathlib import Path
import subprocess
import sys
from typing import Dict, Any, List
import time
import threading
import queue

class DeployManager:
    """Gerenciador de deploy multi-plataforma."""

    def __init__(self):
        self.platform_info = self._detect_platform()
        self.gpu_info = self._detect_gpu()
        self.deployment_options = self._get_deployment_options()
        self.command_queue = queue.Queue()
        self.command_results = {}

    def execute_command_async(self, command: str, key: str):
        """Executa comando de forma ass√≠ncrona."""
        def run_command():
            try:
                result = subprocess.run(
                    command,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=30,
                    cwd=str(Path.cwd())
                )
                self.command_results[key] = {
                    'success': result.returncode == 0,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'returncode': result.returncode
                }
            except subprocess.TimeoutExpired:
                self.command_results[key] = {
                    'success': False,
                    'stdout': '',
                    'stderr': 'Timeout ap√≥s 30 segundos',
                    'returncode': -1
                }
            except Exception as e:
                self.command_results[key] = {
                    'success': False,
                    'stdout': '',
                    'stderr': str(e),
                    'returncode': -1
                }

        thread = threading.Thread(target=run_command, daemon=True)
        thread.start()
        return key

    def get_command_result(self, key: str) -> Dict[str, Any]:
        """Obt√©m resultado de comando executado."""
        return self.command_results.get(key, {'success': None, 'stdout': '', 'stderr': '', 'returncode': None})

    def _detect_platform(self) -> Dict[str, Any]:
        """Detecta plataforma atual."""
        info = {
            'name': 'Desenvolvimento Local',
            'icon': 'üñ•Ô∏è',
            'is_cloud': False,
            'gpu_available': False,
            'memory_limit': 'Ilimitado',
            'timeout_limit': 'Ilimitado',
            'color': 'blue'
        }

        # Google Colab
        if 'COLAB_GPU' in os.environ or 'COLAB_TPU_ADDR' in os.environ:
            info.update({
                'name': 'Google Colab',
                'icon': 'üåê',
                'is_cloud': True,
                'gpu_available': True,
                'memory_limit': 'At√© 25GB',
                'timeout_limit': 'Ilimitado',
                'color': 'orange'
            })

        # Hugging Face Spaces
        elif 'SPACE_ID' in os.environ or 'HF_SPACE' in os.environ:
            info.update({
                'name': 'Hugging Face Spaces',
                'icon': 'ü§ó',
                'is_cloud': True,
                'gpu_available': True,
                'memory_limit': 'At√© 16GB',
                'timeout_limit': 'Ilimitado',
                'color': 'purple'
            })

        # Streamlit Cloud
        elif 'STREAMLIT_SERVER_HEADLESS' in os.environ:
            info.update({
                'name': 'Streamlit Cloud',
                'icon': '‚òÅÔ∏è',
                'is_cloud': True,
                'gpu_available': False,
                'memory_limit': '~1GB',
                'timeout_limit': '10-15 min',
                'color': 'green'
            })

        return info

    def _detect_gpu(self) -> Dict[str, Any]:
        """Detecta GPU dispon√≠vel."""
        gpu_info = {
            'available': False,
            'name': 'CPU',
            'memory_gb': 0,
            'type': 'cpu'
        }

        try:
            import torch
            gpu_info['available'] = torch.cuda.is_available()
            if gpu_info['available']:
                gpu_info.update({
                    'name': torch.cuda.get_device_name(0),
                    'memory_gb': round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 1),
                    'type': 'cuda'
                })
        except ImportError:
            pass

        return gpu_info

    def _get_deployment_options(self) -> List[Dict[str, Any]]:
        """Retorna op√ß√µes de deploy dispon√≠veis."""
        return [
            {
                'name': 'Streamlit Cloud',
                'icon': '‚òÅÔ∏è',
                'description': 'Deploy r√°pido e simples (CPU-only)',
                'pros': ['F√°cil setup', 'Gratuito', 'Integra√ß√£o GitHub'],
                'cons': ['Sem GPU', 'Limita√ß√µes de mem√≥ria', 'Timeout curto'],
                'best_for': ['Demonstra√ß√µes b√°sicas', 'Testes iniciais'],
                'requirements_file': 'requirements_streamlit_cloud.txt',
                'main_file': 'app_integrada.py',
                'url': 'https://share.streamlit.io'
            },
            {
                'name': 'Google Colab',
                'icon': 'üåê',
                'description': 'GPU/TPU gratuito para demonstra√ß√µes',
                'pros': ['GPU gratuito', 'Recursos ilimitados', 'Compartilhamento f√°cil'],
                'cons': ['Setup manual', 'Inst√°vel para produ√ß√£o'],
                'best_for': ['Demonstra√ß√µes com GPU', 'Testes avan√ßados'],
                'notebook_file': 'Algoritmos_Visualizador_Colab.ipynb',
                'url': 'https://colab.research.google.com'
            },
            {
                'name': 'Hugging Face Spaces',
                'icon': 'ü§ó',
                'description': 'Deploy profissional com GPU persistente',
                'pros': ['GPU persistente', 'Escal√°vel', 'API integrada'],
                'cons': ['Setup mais complexo', 'Limita√ß√µes de espa√ßo'],
                'best_for': ['Produ√ß√£o', 'Modelos ML', 'API deployments'],
                'requirements_file': 'requirements_huggingface_spaces.txt',
                'main_file': 'app_integrada.py',
                'readme_file': 'HuggingFace_Spaces_README.md',
                'url': 'https://huggingface.co/spaces'
            }
        ]

    def run_compatibility_check(self) -> Dict[str, Any]:
        """Executa verifica√ß√£o de compatibilidade completa."""
        results = {
            'platform': self.platform_info,
            'gpu': self.gpu_info,
            'dependencies': {},
            'files': {},
            'recommendations': []
        }

        # Verificar depend√™ncias cr√≠ticas
        critical_deps = ['streamlit', 'torch', 'numpy', 'pandas', 'matplotlib', 'plotly']
        for dep in critical_deps:
            try:
                __import__(dep)
                results['dependencies'][dep] = {'status': 'ok', 'version': getattr(__import__(dep), '__version__', 'unknown')}
            except ImportError:
                results['dependencies'][dep] = {'status': 'missing', 'version': None}

        # Verificar arquivos cr√≠ticos
        critical_files = [
            'app_integrada.py',
            'requirements_streamlit_cloud.txt',
            'colab_setup.py',
            'requirements_huggingface_spaces.txt'
        ]
        for file_path in critical_files:
            path = Path(file_path)
            results['files'][file_path] = path.exists()

        # Recomenda√ß√µes
        if not self.gpu_info['available'] and self.platform_info['name'] == 'Local Development':
            results['recommendations'].append("Considere usar Google Colab ou Hugging Face Spaces para funcionalidades GPU")

        if self.platform_info['name'] == 'Streamlit Cloud':
            results['recommendations'].append("Funcionalidades avan√ßadas de GPU n√£o dispon√≠veis nesta plataforma")

        return results

    def get_system_info(self) -> Dict[str, Any]:
        """Obt√©m informa√ß√µes detalhadas do sistema."""
        return {
            'python_version': platform.python_version(),
            'system': platform.system(),
            'machine': platform.machine(),
            'processor': platform.processor(),
            'platform': platform.platform(),
            'environment_vars': {k: v for k, v in os.environ.items() if k.startswith(('STREAMLIT_', 'COLAB_', 'SPACE_', 'HF_'))}
        }

def show_deploy_dashboard():
    """Exibe dashboard de deploy na aplica√ß√£o Streamlit."""
    st.header("üöÄ Deploy Multi-Plataforma")

    deploy_manager = DeployManager()

    # Status da Plataforma Atual
    st.subheader(f"{deploy_manager.platform_info['icon']} Plataforma Atual: {deploy_manager.platform_info['name']}")

    col1, col2, col3 = st.columns(3)

    with col1:
        gpu_status = "Sim" if deploy_manager.gpu_info['available'] else "N√£o"
        st.metric("GPU Dispon√≠vel", gpu_status)
        if deploy_manager.gpu_info['available']:
            st.caption(f"{deploy_manager.gpu_info['name']} ({deploy_manager.gpu_info['memory_gb']}GB)")

    with col2:
        st.metric("Mem√≥ria Limite", deploy_manager.platform_info['memory_limit'])

    with col3:
        st.metric("Timeout", deploy_manager.platform_info['timeout_limit'])

    # CONTROLE INTERATIVO - Nova se√ß√£o
    st.subheader("üéÆ Controle Interativo")

    tab1, tab2, tab3, tab4 = st.tabs(["üîç Verifica√ß√£o", "‚öôÔ∏è Configura√ß√£o", "üöÄ Inicializa√ß√£o", "üìä Sistema"])

    with tab1:
        show_verification_tab(deploy_manager)

    with tab2:
        show_configuration_tab(deploy_manager)

    with tab3:
        show_initialization_tab(deploy_manager)

    with tab4:
        show_system_tab(deploy_manager)

    # Funcionalidades Otimizadas (mantido)
    st.subheader("üéØ Funcionalidades Dispon√≠veis")

    features = {
        'visualizacoes': 'üìä Visualiza√ß√µes Interativas',
        'redes_neurais': 'üß† Redes Neurais Avan√ßadas',
        'arte_generativa': 'üé® Arte Generativa',
        'competicoes': 'üèÜ Competi√ß√µes Globais',
        'exercicios': 'üìù Exerc√≠cios Pr√°ticos',
        'busca_web': 'üîç Busca Web Integrada'
    }

    if deploy_manager.platform_info['name'] == 'Streamlit Cloud':
        available_features = ['visualizacoes', 'exercicios', 'busca_web']
    elif deploy_manager.platform_info['name'] in ['Google Colab', 'Hugging Face Spaces']:
        available_features = list(features.keys())
    else:
        available_features = list(features.keys())

    cols = st.columns(2)
    for i, feature_key in enumerate(features.keys()):
        with cols[i % 2]:
            if feature_key in available_features:
                st.success(f"‚úÖ {features[feature_key]}")
            else:
                st.warning(f"‚ö†Ô∏è {features[feature_key]} (Limitado)")

    # Op√ß√µes de Deploy (mantido)
    st.subheader("üåê Op√ß√µes de Deploy")

    for option in deploy_manager.deployment_options:
        with st.expander(f"{option['icon']} {option['name']} - {option['description']}"):

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**‚úÖ Vantagens:**")
                for pro in option['pros']:
                    st.markdown(f"‚Ä¢ {pro}")

            with col2:
                st.markdown("**‚ö†Ô∏è Limita√ß√µes:**")
                for con in option['cons']:
                    st.markdown(f"‚Ä¢ {con}")

            st.markdown(f"**üéØ Ideal para:** {', '.join(option['best_for'])}")

            # Bot√µes de a√ß√£o
            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button(f"üìã Ver Requirements", key=f"req_{option['name']}"):
                    req_file = option.get('requirements_file')
                    if req_file and Path(req_file).exists():
                        with open(req_file, 'r') as f:
                            st.code(f.read(), language='text')
                    else:
                        st.warning("Arquivo de requirements n√£o encontrado")

            with col2:
                if 'notebook_file' in option:
                    if st.button(f"üìì Abrir Notebook", key=f"nb_{option['name']}"):
                        st.markdown(f"[Abrir no Colab]({option['url']})")
                        st.info("Fa√ßa upload do arquivo: Algoritmos_Visualizador_Colab.ipynb")
                else:
                    if st.button(f"üöÄ Deploy Guide", key=f"deploy_{option['name']}"):
                        st.markdown(f"[Ir para {option['name']}]({option['url']})")

            with col3:
                if 'readme_file' in option:
                    if st.button(f"üìñ Ver README", key=f"readme_{option['name']}"):
                        readme_file = option['readme_file']
                        if Path(readme_file).exists():
                            with open(readme_file, 'r') as f:
                                st.markdown(f.read())
                        else:
                            st.warning("README n√£o encontrado")

    # Guia de Migra√ß√£o (mantido)
    st.subheader("üîÑ Guia de Migra√ß√£o")

    st.markdown("""
    **De Local ‚Üí Cloud:**

    1. **Streamlit Cloud** (Recomendado para come√ßar):
       - Commit no GitHub
       - Deploy autom√°tico
       - Sem configura√ß√£o complexa

    2. **Google Colab** (Para demonstra√ß√µes com GPU):
       - Upload do notebook
       - Execu√ß√£o imediata
       - Compartilhamento f√°cil

    3. **Hugging Face Spaces** (Para produ√ß√£o):
       - Deploy profissional
       - GPU persistente
       - Escal√°vel

    **üí° Dica:** Comece com Streamlit Cloud e migre para outras plataformas conforme necess√°rio.
    """)

def get_platform_config() -> Dict[str, Any]:
    """Retorna configura√ß√£o otimizada para a plataforma atual."""
    deploy_manager = DeployManager()
    return {
        'platform': deploy_manager.platform_info,
        'gpu': deploy_manager.gpu_info,
        'features_enabled': _get_enabled_features(deploy_manager),
        'cache_optimized': deploy_manager.platform_info['is_cloud']
    }

def _get_enabled_features(deploy_manager: DeployManager) -> List[str]:
    """Retorna lista de funcionalidades habilitadas."""
    base_features = ['visualizacoes', 'exercicios', 'busca_web']

    if deploy_manager.gpu_info['available']:
        base_features.extend(['redes_neurais', 'arte_generativa', 'competicoes'])

        return base_features

    def run_compatibility_check(self) -> Dict[str, Any]:
        """Executa verifica√ß√£o de compatibilidade completa."""
        results = {
            'platform': self.platform_info,
            'gpu': self.gpu_info,
            'dependencies': {},
            'files': {},
            'recommendations': []
        }

        # Verificar depend√™ncias cr√≠ticas
        critical_deps = ['streamlit', 'torch', 'numpy', 'pandas', 'matplotlib', 'plotly']
        for dep in critical_deps:
            try:
                __import__(dep)
                results['dependencies'][dep] = {'status': 'ok', 'version': getattr(__import__(dep), '__version__', 'unknown')}
            except ImportError:
                results['dependencies'][dep] = {'status': 'missing', 'version': None}

        # Verificar arquivos cr√≠ticos
        critical_files = [
            'app_integrada.py',
            'requirements_streamlit_cloud.txt',
            'colab_setup.py',
            'requirements_huggingface_spaces.txt'
        ]
        for file_path in critical_files:
            path = Path(file_path)
            results['files'][file_path] = path.exists()

        # Recomenda√ß√µes
        if not self.gpu_info['available'] and self.platform_info['name'] == 'Local Development':
            results['recommendations'].append("Considere usar Google Colab ou Hugging Face Spaces para funcionalidades GPU")

        if self.platform_info['name'] == 'Streamlit Cloud':
            results['recommendations'].append("Funcionalidades avan√ßadas de GPU n√£o dispon√≠veis nesta plataforma")

        return results

    def get_system_info(self) -> Dict[str, Any]:
        """Obt√©m informa√ß√µes detalhadas do sistema."""
        return {
            'python_version': platform.python_version(),
            'system': platform.system(),
            'machine': platform.machine(),
            'processor': platform.processor(),
            'platform': platform.platform(),
            'environment_vars': {k: v for k, v in os.environ.items() if k.startswith(('STREAMLIT_', 'COLAB_', 'SPACE_', 'HF_'))}
        }# Fun√ß√£o para integrar ao app_integrada.py
def integrar_deploy_module():
    """
    Fun√ß√£o para integrar o m√≥dulo de deploy ao app_integrada.py

    Uso no app_integrada.py:
    ```python
    from deploy_multi_plataforma import show_deploy_dashboard, get_platform_config

    # Na fun√ß√£o main ou em uma aba espec√≠fica
    if st.sidebar.button("üöÄ Deploy Options"):
        show_deploy_dashboard()

    # Para obter configura√ß√£o da plataforma
    platform_config = get_platform_config()
    ```
    """
    pass


def show_verification_tab(deploy_manager: DeployManager):
    """Aba de verifica√ß√£o de compatibilidade."""
    st.markdown("### üîç Verifica√ß√£o de Compatibilidade")

    if st.button("üöÄ Executar Verifica√ß√£o Completa", type="primary"):
        with st.spinner("Verificando sistema..."):
            progress_bar = st.progress(0)
            status_text = st.empty()

            # Verifica√ß√£o passo a passo
            steps = [
                ("Detectando plataforma", 20),
                ("Verificando GPU", 40),
                ("Verificando depend√™ncias", 60),
                ("Verificando arquivos", 80),
                ("Gerando recomenda√ß√µes", 100)
            ]

            results = deploy_manager.run_compatibility_check()

            for step, progress in steps:
                status_text.text(f"üîÑ {step}...")
                progress_bar.progress(progress / 100)
                time.sleep(0.5)

            progress_bar.empty()
            status_text.empty()

        # Resultados
        st.success("‚úÖ Verifica√ß√£o conclu√≠da!")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**üìç Plataforma:**")
            st.info(f"{results['platform']['icon']} {results['platform']['name']}")

            st.markdown("**üéÆ GPU:**")
            if results['gpu']['available']:
                st.success(f"‚úÖ {results['gpu']['name']} ({results['gpu']['memory_gb']}GB)")
            else:
                st.warning("‚ö†Ô∏è N√£o dispon√≠vel")

        with col2:
            st.markdown("**üì¶ Depend√™ncias:**")
            for dep, info in results['dependencies'].items():
                if info['status'] == 'ok':
                    st.success(f"‚úÖ {dep} v{info['version']}")
                else:
                    st.error(f"‚ùå {dep} - Faltando")

        st.markdown("**üìÅ Arquivos Cr√≠ticos:**")
        for file_path, exists in results['files'].items():
            if exists:
                st.success(f"‚úÖ {file_path}")
            else:
                st.error(f"‚ùå {file_path} - N√£o encontrado")

        if results['recommendations']:
            st.markdown("**üí° Recomenda√ß√µes:**")
            for rec in results['recommendations']:
                st.info(f"üí° {rec}")


def show_configuration_tab(deploy_manager: DeployManager):
    """Aba de configura√ß√£o do sistema."""
    st.markdown("### ‚öôÔ∏è Configura√ß√£o do Sistema")

    st.markdown("**üîß Par√¢metros de Inicializa√ß√£o:**")

    col1, col2 = st.columns(2)

    with col1:
        force_platform = st.selectbox(
            "For√ßar Plataforma:",
            ["Auto-detectar", "Google Colab", "Hugging Face Spaces", "Local"],
            index=0
        )

        debug_mode = st.checkbox("Modo Debug", value=False)
        cache_enabled = st.checkbox("Cache Habilitado", value=True)

    with col2:
        port = st.number_input("Porta do Servidor", value=8501, min_value=8000, max_value=9000)
        timeout = st.number_input("Timeout (segundos)", value=30, min_value=10, max_value=300)

    if st.button("üíæ Salvar Configura√ß√µes"):
        st.success("‚úÖ Configura√ß√µes salvas!")
        st.rerun()

    st.markdown("---")

    st.markdown("**üîê Configura√ß√µes de API:**")

    with st.expander("API Keys (Opcional)"):
        tavily_key = st.text_input("Tavily API Key", type="password", placeholder="tvly-...")
        github_token = st.text_input("GitHub Token", type="password", placeholder="ghp_...")

        if st.button("üîí Salvar API Keys"):
            st.success("‚úÖ API Keys configuradas!")
            st.info("‚ö†Ô∏è As chaves s√£o armazenadas apenas na sess√£o atual")


def show_initialization_tab(deploy_manager: DeployManager):
    """Aba de inicializa√ß√£o e controle."""
    st.markdown("### üöÄ Inicializa√ß√£o e Controle")

    st.markdown("**üéØ Comandos Dispon√≠veis:**")

    # Inicializa√ß√£o autom√°tica
    col1, col2 = st.columns(2)

    with col1:
        if st.button("üöÄ Iniciar App (Auto)", type="primary"):
            with st.spinner("Iniciando aplica√ß√£o..."):
                cmd_key = deploy_manager.execute_command_async("python iniciar.py", "start_app")
                time.sleep(2)

                result = deploy_manager.get_command_result(cmd_key)
                if result['success'] is not None:
                    if result['success']:
                        st.success("‚úÖ Aplica√ß√£o iniciada com sucesso!")
                        st.info("üåê Acesse: http://localhost:8501")
                    else:
                        st.error("‚ùå Erro ao iniciar aplica√ß√£o")
                        st.code(result['stderr'])
                else:
                    st.warning("‚è≥ Comando em execu√ß√£o...")

    with col2:
        if st.button("üîç Verificar Plataforma"):
            with st.spinner("Verificando..."):
                cmd_key = deploy_manager.execute_command_async("python multi_platform_launcher.py", "check_platform")
                time.sleep(3)

                result = deploy_manager.get_command_result(cmd_key)
                if result['success'] is not None:
                    if result['success']:
                        st.success("‚úÖ Verifica√ß√£o conclu√≠da!")
                        # Mostrar output
                        with st.expander("üìÑ Detalhes da Verifica√ß√£o"):
                            st.code(result['stdout'], language='text')
                    else:
                        st.error("‚ùå Erro na verifica√ß√£o")
                        st.code(result['stderr'])

    st.markdown("---")

    st.markdown("**üõ†Ô∏è Comandos Manuais:**")

    manual_commands = {
        "Verificar depend√™ncias": "python -c \"import torch, streamlit; print('OK')\"",
        "Limpar cache": "rm -rf __pycache__ .streamlit/cache",
        "Testar GPU": "python -c \"import torch; print(torch.cuda.is_available())\"",
        "Ver logs": "tail -20 .streamlit/logs/streamlit.log 2>/dev/null || echo 'Sem logs'"
    }

    selected_cmd = st.selectbox("Selecione comando:", list(manual_commands.keys()))

    if st.button("‚ñ∂Ô∏è Executar Comando"):
        cmd = manual_commands[selected_cmd]
        with st.spinner(f"Executando: {cmd}"):
            cmd_key = deploy_manager.execute_command_async(cmd, f"manual_{selected_cmd}")

            # Aguardar resultado
            for _ in range(10):  # 5 segundos timeout
                time.sleep(0.5)
                result = deploy_manager.get_command_result(cmd_key)
                if result['success'] is not None:
                    break

            if result['success'] is not None:
                if result['success']:
                    st.success("‚úÖ Comando executado com sucesso!")
                    if result['stdout'].strip():
                        st.code(result['stdout'], language='text')
                else:
                    st.error("‚ùå Erro na execu√ß√£o")
                    if result['stderr'].strip():
                        st.code(result['stderr'], language='text')
            else:
                st.warning("‚è≥ Comando ainda em execu√ß√£o...")


def show_system_tab(deploy_manager: DeployManager):
    """Aba de informa√ß√µes do sistema."""
    st.markdown("### üìä Informa√ß√µes do Sistema")

    system_info = deploy_manager.get_system_info()

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**üêç Python:**")
        st.info(system_info['python_version'])

        st.markdown("**üíª Sistema:**")
        st.info(f"{system_info['system']} {system_info['machine']}")

        st.markdown("**‚öôÔ∏è Processador:**")
        st.info(system_info['processor'] or "N√£o identificado")

    with col2:
        st.markdown("**üèóÔ∏è Plataforma:**")
        st.info(system_info['platform'])

        st.markdown("**üîß Ambiente Streamlit:**")
        streamlit_vars = {k: v for k, v in system_info['environment_vars'].items() if k.startswith('STREAMLIT_')}
        if streamlit_vars:
            for k, v in streamlit_vars.items():
                st.code(f"{k}={v}")
        else:
            st.info("Nenhuma vari√°vel Streamlit detectada")

    st.markdown("---")

    st.markdown("**üìÇ Arquivos do Projeto:**")

    project_files = [
        "app_integrada.py",
        "iniciar.py",
        "multi_platform_launcher.py",
        "requirements.txt",
        "README_MULTIPLATFORMA.md"
    ]

    for file_path in project_files:
        path = Path(file_path)
        if path.exists():
            size = path.stat().st_size
            st.success(f"‚úÖ {file_path} ({size} bytes)")
        else:
            st.error(f"‚ùå {file_path} - N√£o encontrado")

    st.markdown("---")

    st.markdown("**üíæ Recursos do Sistema:**")

    # M√©tricas de recursos (simuladas)
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("CPU Cores", "4")  # Simulado

    with col2:
        st.metric("Mem√≥ria Total", "8GB")  # Simulado

    with col3:
        st.metric("Disco Livre", "50GB")  # Simulado